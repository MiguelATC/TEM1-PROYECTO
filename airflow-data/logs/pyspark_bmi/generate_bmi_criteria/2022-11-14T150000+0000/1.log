[2022-12-13 04:41:30,267] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 04:41:30,282] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 04:41:30,283] {taskinstance.py:1017} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 04:41:30,283] {taskinstance.py:1018} INFO - Starting attempt 1 of 1
[2022-12-13 04:41:30,283] {taskinstance.py:1019} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 04:41:30,290] {taskinstance.py:1038} INFO - Executing <Task(PythonOperator): generate_bmi_criteria> on 2022-11-14T15:00:00+00:00
[2022-12-13 04:41:30,294] {standard_task_runner.py:51} INFO - Started process 2229 to run task
[2022-12-13 04:41:30,296] {standard_task_runner.py:75} INFO - Running: ['airflow', 'tasks', 'run', 'pyspark_bmi', 'generate_bmi_criteria', '2022-11-14T15:00:00+00:00', '--job-id', '4', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/pyspark_bmi.py', '--cfg-path', '/tmp/tmpcybu2ahq']
[2022-12-13 04:41:30,298] {standard_task_runner.py:76} INFO - Job 4: Subtask generate_bmi_criteria
[2022-12-13 04:41:30,330] {logging_mixin.py:103} INFO - Running <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [running]> on host 1990905622a9
[2022-12-13 04:41:30,365] {taskinstance.py:1232} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=pyspark_bmi
AIRFLOW_CTX_TASK_ID=generate_bmi_criteria
AIRFLOW_CTX_EXECUTION_DATE=2022-11-14T15:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=backfill__2022-11-14T15:00:00+00:00
[2022-12-13 04:41:30,854] {pyspark_bmi.py:61} INFO - Job submitted successfully. Driver id is driver-20221213044130-0000
[2022-12-13 04:41:43,984] {pyspark_bmi.py:74} INFO - Job is finished. Moving to next task
[2022-12-13 04:41:43,984] {python.py:118} INFO - Done. Returned value was: None
[2022-12-13 04:41:43,992] {taskinstance.py:1142} INFO - Marking task as SUCCESS. dag_id=pyspark_bmi, task_id=generate_bmi_criteria, execution_date=20221114T150000, start_date=20221213T044130, end_date=20221213T044143
[2022-12-13 04:41:44,012] {taskinstance.py:1195} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-12-13 04:41:44,035] {local_task_job.py:118} INFO - Task exited with return code 0
[2022-12-13 04:47:51,552] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 04:47:51,560] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 04:47:51,560] {taskinstance.py:1017} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 04:47:51,560] {taskinstance.py:1018} INFO - Starting attempt 1 of 1
[2022-12-13 04:47:51,560] {taskinstance.py:1019} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 04:47:51,570] {taskinstance.py:1038} INFO - Executing <Task(PythonOperator): generate_bmi_criteria> on 2022-11-14T15:00:00+00:00
[2022-12-13 04:47:51,574] {standard_task_runner.py:51} INFO - Started process 2053 to run task
[2022-12-13 04:47:51,576] {standard_task_runner.py:75} INFO - Running: ['airflow', 'tasks', 'run', 'pyspark_bmi', 'generate_bmi_criteria', '2022-11-14T15:00:00+00:00', '--job-id', '4', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/pyspark_bmi.py', '--cfg-path', '/tmp/tmpa_p9zdaa']
[2022-12-13 04:47:51,577] {standard_task_runner.py:76} INFO - Job 4: Subtask generate_bmi_criteria
[2022-12-13 04:47:51,609] {logging_mixin.py:103} INFO - Running <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [running]> on host 457b414c86a4
[2022-12-13 04:47:51,645] {taskinstance.py:1232} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=pyspark_bmi
AIRFLOW_CTX_TASK_ID=generate_bmi_criteria
AIRFLOW_CTX_EXECUTION_DATE=2022-11-14T15:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=backfill__2022-11-14T15:00:00+00:00
[2022-12-13 04:47:52,203] {pyspark_bmi.py:61} INFO - Job submitted successfully. Driver id is driver-20221213044752-0000
[2022-12-13 04:48:04,317] {pyspark_bmi.py:74} INFO - Job is finished. Moving to next task
[2022-12-13 04:48:04,318] {python.py:118} INFO - Done. Returned value was: None
[2022-12-13 04:48:04,331] {taskinstance.py:1142} INFO - Marking task as SUCCESS. dag_id=pyspark_bmi, task_id=generate_bmi_criteria, execution_date=20221114T150000, start_date=20221213T044751, end_date=20221213T044804
[2022-12-13 04:48:04,363] {taskinstance.py:1195} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-12-13 04:48:04,389] {local_task_job.py:118} INFO - Task exited with return code 0
[2022-12-13 06:26:59,483] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 06:26:59,626] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 06:26:59,627] {taskinstance.py:1017} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 06:26:59,627] {taskinstance.py:1018} INFO - Starting attempt 1 of 1
[2022-12-13 06:26:59,627] {taskinstance.py:1019} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 06:26:59,718] {taskinstance.py:1038} INFO - Executing <Task(PythonOperator): generate_bmi_criteria> on 2022-11-14T15:00:00+00:00
[2022-12-13 06:26:59,722] {standard_task_runner.py:51} INFO - Started process 2278 to run task
[2022-12-13 06:26:59,724] {standard_task_runner.py:75} INFO - Running: ['airflow', 'tasks', 'run', 'pyspark_bmi', 'generate_bmi_criteria', '2022-11-14T15:00:00+00:00', '--job-id', '5', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/pyspark_bmi.py', '--cfg-path', '/tmp/tmpbd7w66iq']
[2022-12-13 06:26:59,726] {standard_task_runner.py:76} INFO - Job 5: Subtask generate_bmi_criteria
[2022-12-13 06:26:59,839] {logging_mixin.py:103} INFO - Running <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [running]> on host deeb3cfa4430
[2022-12-13 06:26:59,957] {taskinstance.py:1232} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=pyspark_bmi
AIRFLOW_CTX_TASK_ID=generate_bmi_criteria
AIRFLOW_CTX_EXECUTION_DATE=2022-11-14T15:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=backfill__2022-11-14T15:00:00+00:00
[2022-12-13 06:27:02,393] {pyspark_bmi.py:61} INFO - Job submitted successfully. Driver id is driver-20221213062701-0000
[2022-12-13 06:27:11,502] {taskinstance.py:1396} ERROR - exceptions must derive from BaseException
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1086, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1260, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1300, in _execute_task
    result = task_copy.execute(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 117, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 128, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/pyspark_bmi.py", line 70, in generate_bmi_criteria_spark
    raise 'Error running job'
TypeError: exceptions must derive from BaseException
[2022-12-13 06:27:11,505] {taskinstance.py:1440} INFO - Marking task as FAILED. dag_id=pyspark_bmi, task_id=generate_bmi_criteria, execution_date=20221114T150000, start_date=20221213T062659, end_date=20221213T062711
[2022-12-13 06:27:11,555] {local_task_job.py:118} INFO - Task exited with return code 1
[2022-12-13 06:35:26,143] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 06:35:26,152] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 06:35:26,152] {taskinstance.py:1017} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 06:35:26,152] {taskinstance.py:1018} INFO - Starting attempt 1 of 1
[2022-12-13 06:35:26,153] {taskinstance.py:1019} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 06:35:26,162] {taskinstance.py:1038} INFO - Executing <Task(PythonOperator): generate_bmi_criteria> on 2022-11-14T15:00:00+00:00
[2022-12-13 06:35:26,165] {standard_task_runner.py:51} INFO - Started process 3218 to run task
[2022-12-13 06:35:26,167] {standard_task_runner.py:75} INFO - Running: ['airflow', 'tasks', 'run', 'pyspark_bmi', 'generate_bmi_criteria', '2022-11-14T15:00:00+00:00', '--job-id', '4', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/pyspark_bmi.py', '--cfg-path', '/tmp/tmp7sgdpk3g']
[2022-12-13 06:35:26,169] {standard_task_runner.py:76} INFO - Job 4: Subtask generate_bmi_criteria
[2022-12-13 06:35:26,203] {logging_mixin.py:103} INFO - Running <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [running]> on host b7822b6a2db4
[2022-12-13 06:35:26,235] {taskinstance.py:1232} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=pyspark_bmi
AIRFLOW_CTX_TASK_ID=generate_bmi_criteria
AIRFLOW_CTX_EXECUTION_DATE=2022-11-14T15:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=backfill__2022-11-14T15:00:00+00:00
[2022-12-13 06:35:26,747] {pyspark_bmi.py:61} INFO - Job submitted successfully. Driver id is driver-20221213063526-0000
[2022-12-13 06:35:38,860] {pyspark_bmi.py:74} INFO - Job is finished. Moving to next task
[2022-12-13 06:35:38,861] {python.py:118} INFO - Done. Returned value was: None
[2022-12-13 06:35:38,871] {taskinstance.py:1142} INFO - Marking task as SUCCESS. dag_id=pyspark_bmi, task_id=generate_bmi_criteria, execution_date=20221114T150000, start_date=20221213T063526, end_date=20221213T063538
[2022-12-13 06:35:38,896] {taskinstance.py:1195} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-12-13 06:35:38,904] {local_task_job.py:118} INFO - Task exited with return code 0
[2022-12-13 07:00:58,162] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 07:00:58,180] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 07:00:58,180] {taskinstance.py:1017} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 07:00:58,181] {taskinstance.py:1018} INFO - Starting attempt 1 of 1
[2022-12-13 07:00:58,181] {taskinstance.py:1019} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 07:00:58,191] {taskinstance.py:1038} INFO - Executing <Task(PythonOperator): generate_bmi_criteria> on 2022-11-14T15:00:00+00:00
[2022-12-13 07:00:58,195] {standard_task_runner.py:51} INFO - Started process 2164 to run task
[2022-12-13 07:00:58,197] {standard_task_runner.py:75} INFO - Running: ['airflow', 'tasks', 'run', 'pyspark_bmi', 'generate_bmi_criteria', '2022-11-14T15:00:00+00:00', '--job-id', '5', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/pyspark_bmi.py', '--cfg-path', '/tmp/tmp4amk1uza']
[2022-12-13 07:00:58,200] {standard_task_runner.py:76} INFO - Job 5: Subtask generate_bmi_criteria
[2022-12-13 07:00:58,236] {logging_mixin.py:103} INFO - Running <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [running]> on host 333952be7749
[2022-12-13 07:00:58,271] {taskinstance.py:1232} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=pyspark_bmi
AIRFLOW_CTX_TASK_ID=generate_bmi_criteria
AIRFLOW_CTX_EXECUTION_DATE=2022-11-14T15:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=backfill__2022-11-14T15:00:00+00:00
[2022-12-13 07:00:58,829] {pyspark_bmi.py:61} INFO - Job submitted successfully. Driver id is driver-20221213070058-0000
[2022-12-13 07:01:11,967] {pyspark_bmi.py:74} INFO - Job is finished. Moving to next task
[2022-12-13 07:01:11,967] {python.py:118} INFO - Done. Returned value was: None
[2022-12-13 07:01:11,976] {taskinstance.py:1142} INFO - Marking task as SUCCESS. dag_id=pyspark_bmi, task_id=generate_bmi_criteria, execution_date=20221114T150000, start_date=20221213T070058, end_date=20221213T070111
[2022-12-13 07:01:11,996] {taskinstance.py:1195} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-12-13 07:01:12,017] {local_task_job.py:118} INFO - Task exited with return code 0
[2022-12-13 07:12:34,765] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 07:12:34,779] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 07:12:34,780] {taskinstance.py:1017} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 07:12:34,780] {taskinstance.py:1018} INFO - Starting attempt 1 of 1
[2022-12-13 07:12:34,780] {taskinstance.py:1019} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 07:12:34,787] {taskinstance.py:1038} INFO - Executing <Task(PythonOperator): generate_bmi_criteria> on 2022-11-14T15:00:00+00:00
[2022-12-13 07:12:34,792] {standard_task_runner.py:51} INFO - Started process 1678 to run task
[2022-12-13 07:12:34,794] {standard_task_runner.py:75} INFO - Running: ['airflow', 'tasks', 'run', 'pyspark_bmi', 'generate_bmi_criteria', '2022-11-14T15:00:00+00:00', '--job-id', '4', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/pyspark_bmi.py', '--cfg-path', '/tmp/tmpg5t09p8y']
[2022-12-13 07:12:34,796] {standard_task_runner.py:76} INFO - Job 4: Subtask generate_bmi_criteria
[2022-12-13 07:12:34,830] {logging_mixin.py:103} INFO - Running <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [running]> on host f5c4f12786d0
[2022-12-13 07:12:34,863] {taskinstance.py:1232} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=pyspark_bmi
AIRFLOW_CTX_TASK_ID=generate_bmi_criteria
AIRFLOW_CTX_EXECUTION_DATE=2022-11-14T15:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=backfill__2022-11-14T15:00:00+00:00
[2022-12-13 07:12:35,346] {pyspark_bmi.py:61} INFO - Job submitted successfully. Driver id is driver-20221213071235-0000
[2022-12-13 07:12:45,445] {pyspark_bmi.py:74} INFO - Job is finished. Moving to next task
[2022-12-13 07:12:45,446] {python.py:118} INFO - Done. Returned value was: None
[2022-12-13 07:12:45,453] {taskinstance.py:1142} INFO - Marking task as SUCCESS. dag_id=pyspark_bmi, task_id=generate_bmi_criteria, execution_date=20221114T150000, start_date=20221213T071234, end_date=20221213T071245
[2022-12-13 07:12:45,473] {taskinstance.py:1195} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-12-13 07:12:45,506] {local_task_job.py:118} INFO - Task exited with return code 0
[2022-12-13 15:34:07,444] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 15:34:07,457] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 15:34:07,457] {taskinstance.py:1017} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 15:34:07,458] {taskinstance.py:1018} INFO - Starting attempt 1 of 1
[2022-12-13 15:34:07,458] {taskinstance.py:1019} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 15:34:07,471] {taskinstance.py:1038} INFO - Executing <Task(PythonOperator): generate_bmi_criteria> on 2022-11-14T15:00:00+00:00
[2022-12-13 15:34:07,475] {standard_task_runner.py:51} INFO - Started process 2463 to run task
[2022-12-13 15:34:07,477] {standard_task_runner.py:75} INFO - Running: ['airflow', 'tasks', 'run', 'pyspark_bmi', 'generate_bmi_criteria', '2022-11-14T15:00:00+00:00', '--job-id', '5', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/pyspark_bmi.py', '--cfg-path', '/tmp/tmpsh_ienjh']
[2022-12-13 15:34:07,480] {standard_task_runner.py:76} INFO - Job 5: Subtask generate_bmi_criteria
[2022-12-13 15:34:07,519] {logging_mixin.py:103} INFO - Running <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [running]> on host 561e4a6a919b
[2022-12-13 15:34:07,558] {taskinstance.py:1232} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=pyspark_bmi
AIRFLOW_CTX_TASK_ID=generate_bmi_criteria
AIRFLOW_CTX_EXECUTION_DATE=2022-11-14T15:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=backfill__2022-11-14T15:00:00+00:00
[2022-12-13 15:34:08,131] {pyspark_bmi.py:61} INFO - Job submitted successfully. Driver id is driver-20221213153408-0000
[2022-12-13 15:34:20,258] {pyspark_bmi.py:74} INFO - Job is finished. Moving to next task
[2022-12-13 15:34:20,258] {python.py:118} INFO - Done. Returned value was: None
[2022-12-13 15:34:20,267] {taskinstance.py:1142} INFO - Marking task as SUCCESS. dag_id=pyspark_bmi, task_id=generate_bmi_criteria, execution_date=20221114T150000, start_date=20221213T153407, end_date=20221213T153420
[2022-12-13 15:34:20,286] {taskinstance.py:1195} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-12-13 15:34:20,328] {local_task_job.py:118} INFO - Task exited with return code 0
[2022-12-13 20:09:42,003] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 20:09:42,015] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 20:09:42,015] {taskinstance.py:1017} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 20:09:42,015] {taskinstance.py:1018} INFO - Starting attempt 1 of 1
[2022-12-13 20:09:42,016] {taskinstance.py:1019} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 20:09:42,026] {taskinstance.py:1038} INFO - Executing <Task(PythonOperator): generate_bmi_criteria> on 2022-11-14T15:00:00+00:00
[2022-12-13 20:09:42,030] {standard_task_runner.py:51} INFO - Started process 3549 to run task
[2022-12-13 20:09:42,033] {standard_task_runner.py:75} INFO - Running: ['airflow', 'tasks', 'run', 'pyspark_bmi', 'generate_bmi_criteria', '2022-11-14T15:00:00+00:00', '--job-id', '5', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/pyspark_bmi.py', '--cfg-path', '/tmp/tmpolz__xsj']
[2022-12-13 20:09:42,035] {standard_task_runner.py:76} INFO - Job 5: Subtask generate_bmi_criteria
[2022-12-13 20:09:42,071] {logging_mixin.py:103} INFO - Running <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [running]> on host 1ccb25249778
[2022-12-13 20:09:42,102] {taskinstance.py:1232} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=pyspark_bmi
AIRFLOW_CTX_TASK_ID=generate_bmi_criteria
AIRFLOW_CTX_EXECUTION_DATE=2022-11-14T15:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=backfill__2022-11-14T15:00:00+00:00
[2022-12-13 20:09:42,623] {pyspark_bmi.py:61} INFO - Job submitted successfully. Driver id is driver-20221213200942-0000
[2022-12-13 20:09:51,728] {taskinstance.py:1396} ERROR - exceptions must derive from BaseException
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1086, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1260, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1300, in _execute_task
    result = task_copy.execute(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 117, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 128, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/pyspark_bmi.py", line 70, in generate_bmi_criteria_spark
    raise 'Error running job'
TypeError: exceptions must derive from BaseException
[2022-12-13 20:09:51,733] {taskinstance.py:1440} INFO - Marking task as FAILED. dag_id=pyspark_bmi, task_id=generate_bmi_criteria, execution_date=20221114T150000, start_date=20221213T200942, end_date=20221213T200951
[2022-12-13 20:09:51,767] {local_task_job.py:118} INFO - Task exited with return code 1
[2022-12-13 20:15:03,993] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 20:15:04,011] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 20:15:04,012] {taskinstance.py:1017} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 20:15:04,012] {taskinstance.py:1018} INFO - Starting attempt 1 of 1
[2022-12-13 20:15:04,012] {taskinstance.py:1019} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 20:15:04,030] {taskinstance.py:1038} INFO - Executing <Task(PythonOperator): generate_bmi_criteria> on 2022-11-14T15:00:00+00:00
[2022-12-13 20:15:04,036] {standard_task_runner.py:51} INFO - Started process 1653 to run task
[2022-12-13 20:15:04,038] {standard_task_runner.py:75} INFO - Running: ['airflow', 'tasks', 'run', 'pyspark_bmi', 'generate_bmi_criteria', '2022-11-14T15:00:00+00:00', '--job-id', '4', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/pyspark_bmi.py', '--cfg-path', '/tmp/tmphpr42a1l']
[2022-12-13 20:15:04,040] {standard_task_runner.py:76} INFO - Job 4: Subtask generate_bmi_criteria
[2022-12-13 20:15:04,078] {logging_mixin.py:103} INFO - Running <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [running]> on host d0d005b5ea68
[2022-12-13 20:15:04,120] {taskinstance.py:1232} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=pyspark_bmi
AIRFLOW_CTX_TASK_ID=generate_bmi_criteria
AIRFLOW_CTX_EXECUTION_DATE=2022-11-14T15:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=backfill__2022-11-14T15:00:00+00:00
[2022-12-13 20:15:04,669] {pyspark_bmi.py:61} INFO - Job submitted successfully. Driver id is driver-20221213201504-0000
[2022-12-13 20:15:14,773] {pyspark_bmi.py:74} INFO - Job is finished. Moving to next task
[2022-12-13 20:15:14,774] {python.py:118} INFO - Done. Returned value was: None
[2022-12-13 20:15:14,781] {taskinstance.py:1142} INFO - Marking task as SUCCESS. dag_id=pyspark_bmi, task_id=generate_bmi_criteria, execution_date=20221114T150000, start_date=20221213T201503, end_date=20221213T201514
[2022-12-13 20:15:14,804] {taskinstance.py:1195} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-12-13 20:15:14,841] {local_task_job.py:118} INFO - Task exited with return code 0
[2022-12-13 20:59:17,630] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 20:59:17,645] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 20:59:17,645] {taskinstance.py:1017} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 20:59:17,646] {taskinstance.py:1018} INFO - Starting attempt 1 of 1
[2022-12-13 20:59:17,646] {taskinstance.py:1019} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 20:59:17,654] {taskinstance.py:1038} INFO - Executing <Task(PythonOperator): generate_bmi_criteria> on 2022-11-14T15:00:00+00:00
[2022-12-13 20:59:17,657] {standard_task_runner.py:51} INFO - Started process 1684 to run task
[2022-12-13 20:59:17,660] {standard_task_runner.py:75} INFO - Running: ['airflow', 'tasks', 'run', 'pyspark_bmi', 'generate_bmi_criteria', '2022-11-14T15:00:00+00:00', '--job-id', '5', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/pyspark_bmi.py', '--cfg-path', '/tmp/tmpo0mcze4g']
[2022-12-13 20:59:17,663] {standard_task_runner.py:76} INFO - Job 5: Subtask generate_bmi_criteria
[2022-12-13 20:59:17,700] {logging_mixin.py:103} INFO - Running <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [running]> on host 2a0293b83d2d
[2022-12-13 20:59:17,732] {taskinstance.py:1232} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=pyspark_bmi
AIRFLOW_CTX_TASK_ID=generate_bmi_criteria
AIRFLOW_CTX_EXECUTION_DATE=2022-11-14T15:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=backfill__2022-11-14T15:00:00+00:00
[2022-12-13 20:59:18,251] {pyspark_bmi.py:61} INFO - Job submitted successfully. Driver id is driver-20221213205918-0000
[2022-12-13 20:59:26,330] {taskinstance.py:1396} ERROR - exceptions must derive from BaseException
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1086, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1260, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1300, in _execute_task
    result = task_copy.execute(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 117, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 128, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/pyspark_bmi.py", line 70, in generate_bmi_criteria_spark
    raise 'Error running job'
TypeError: exceptions must derive from BaseException
[2022-12-13 20:59:26,334] {taskinstance.py:1440} INFO - Marking task as FAILED. dag_id=pyspark_bmi, task_id=generate_bmi_criteria, execution_date=20221114T150000, start_date=20221213T205917, end_date=20221213T205926
[2022-12-13 20:59:26,371] {local_task_job.py:118} INFO - Task exited with return code 1
[2022-12-13 21:16:45,265] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 21:16:45,277] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 21:16:45,277] {taskinstance.py:1017} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 21:16:45,277] {taskinstance.py:1018} INFO - Starting attempt 1 of 1
[2022-12-13 21:16:45,277] {taskinstance.py:1019} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 21:16:45,285] {taskinstance.py:1038} INFO - Executing <Task(PythonOperator): generate_bmi_criteria> on 2022-11-14T15:00:00+00:00
[2022-12-13 21:16:45,289] {standard_task_runner.py:51} INFO - Started process 1750 to run task
[2022-12-13 21:16:45,291] {standard_task_runner.py:75} INFO - Running: ['airflow', 'tasks', 'run', 'pyspark_bmi', 'generate_bmi_criteria', '2022-11-14T15:00:00+00:00', '--job-id', '4', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/pyspark_bmi.py', '--cfg-path', '/tmp/tmpqq04ggnd']
[2022-12-13 21:16:45,293] {standard_task_runner.py:76} INFO - Job 4: Subtask generate_bmi_criteria
[2022-12-13 21:16:45,325] {logging_mixin.py:103} INFO - Running <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [running]> on host 07717ad0168e
[2022-12-13 21:16:45,353] {taskinstance.py:1232} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=pyspark_bmi
AIRFLOW_CTX_TASK_ID=generate_bmi_criteria
AIRFLOW_CTX_EXECUTION_DATE=2022-11-14T15:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=backfill__2022-11-14T15:00:00+00:00
[2022-12-13 21:16:45,982] {pyspark_bmi.py:61} INFO - Job submitted successfully. Driver id is driver-20221213211645-0000
[2022-12-13 21:16:56,086] {pyspark_bmi.py:74} INFO - Job is finished. Moving to next task
[2022-12-13 21:16:56,086] {python.py:118} INFO - Done. Returned value was: None
[2022-12-13 21:16:56,094] {taskinstance.py:1142} INFO - Marking task as SUCCESS. dag_id=pyspark_bmi, task_id=generate_bmi_criteria, execution_date=20221114T150000, start_date=20221213T211645, end_date=20221213T211656
[2022-12-13 21:16:56,112] {taskinstance.py:1195} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-12-13 21:16:56,122] {local_task_job.py:118} INFO - Task exited with return code 0
[2022-12-13 21:26:55,176] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 21:26:55,185] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 21:26:55,185] {taskinstance.py:1017} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 21:26:55,185] {taskinstance.py:1018} INFO - Starting attempt 1 of 1
[2022-12-13 21:26:55,185] {taskinstance.py:1019} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 21:26:55,195] {taskinstance.py:1038} INFO - Executing <Task(PythonOperator): generate_bmi_criteria> on 2022-11-14T15:00:00+00:00
[2022-12-13 21:26:55,199] {standard_task_runner.py:51} INFO - Started process 1873 to run task
[2022-12-13 21:26:55,201] {standard_task_runner.py:75} INFO - Running: ['airflow', 'tasks', 'run', 'pyspark_bmi', 'generate_bmi_criteria', '2022-11-14T15:00:00+00:00', '--job-id', '4', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/pyspark_bmi.py', '--cfg-path', '/tmp/tmpx0_ks4s6']
[2022-12-13 21:26:55,203] {standard_task_runner.py:76} INFO - Job 4: Subtask generate_bmi_criteria
[2022-12-13 21:26:55,234] {logging_mixin.py:103} INFO - Running <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [running]> on host 28614e99b51d
[2022-12-13 21:26:55,263] {taskinstance.py:1232} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=pyspark_bmi
AIRFLOW_CTX_TASK_ID=generate_bmi_criteria
AIRFLOW_CTX_EXECUTION_DATE=2022-11-14T15:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=backfill__2022-11-14T15:00:00+00:00
[2022-12-13 21:26:55,773] {pyspark_bmi.py:61} INFO - Job submitted successfully. Driver id is driver-20221213212655-0000
[2022-12-13 21:27:17,944] {pyspark_bmi.py:74} INFO - Job is finished. Moving to next task
[2022-12-13 21:27:17,944] {python.py:118} INFO - Done. Returned value was: None
[2022-12-13 21:27:17,952] {taskinstance.py:1142} INFO - Marking task as SUCCESS. dag_id=pyspark_bmi, task_id=generate_bmi_criteria, execution_date=20221114T150000, start_date=20221213T212655, end_date=20221213T212717
[2022-12-13 21:27:17,972] {taskinstance.py:1195} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-12-13 21:27:17,994] {local_task_job.py:118} INFO - Task exited with return code 0
[2022-12-13 22:20:52,266] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 22:20:52,275] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 22:20:52,275] {taskinstance.py:1017} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 22:20:52,276] {taskinstance.py:1018} INFO - Starting attempt 1 of 1
[2022-12-13 22:20:52,276] {taskinstance.py:1019} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 22:20:52,289] {taskinstance.py:1038} INFO - Executing <Task(PythonOperator): generate_bmi_criteria> on 2022-11-14T15:00:00+00:00
[2022-12-13 22:20:52,292] {standard_task_runner.py:51} INFO - Started process 1742 to run task
[2022-12-13 22:20:52,294] {standard_task_runner.py:75} INFO - Running: ['airflow', 'tasks', 'run', 'pyspark_bmi', 'generate_bmi_criteria', '2022-11-14T15:00:00+00:00', '--job-id', '4', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/pyspark_bmi.py', '--cfg-path', '/tmp/tmpdfee8mw2']
[2022-12-13 22:20:52,299] {standard_task_runner.py:76} INFO - Job 4: Subtask generate_bmi_criteria
[2022-12-13 22:20:52,339] {logging_mixin.py:103} INFO - Running <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [running]> on host ea0ed9d3a445
[2022-12-13 22:20:52,381] {taskinstance.py:1232} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=pyspark_bmi
AIRFLOW_CTX_TASK_ID=generate_bmi_criteria
AIRFLOW_CTX_EXECUTION_DATE=2022-11-14T15:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=backfill__2022-11-14T15:00:00+00:00
[2022-12-13 22:20:53,018] {pyspark_bmi.py:61} INFO - Job submitted successfully. Driver id is driver-20221213222052-0000
[2022-12-13 22:21:05,153] {pyspark_bmi.py:74} INFO - Job is finished. Moving to next task
[2022-12-13 22:21:05,154] {python.py:118} INFO - Done. Returned value was: None
[2022-12-13 22:21:05,161] {taskinstance.py:1142} INFO - Marking task as SUCCESS. dag_id=pyspark_bmi, task_id=generate_bmi_criteria, execution_date=20221114T150000, start_date=20221213T222052, end_date=20221213T222105
[2022-12-13 22:21:05,182] {taskinstance.py:1195} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-12-13 22:21:05,193] {local_task_job.py:118} INFO - Task exited with return code 0
[2022-12-13 22:58:23,348] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 22:58:23,366] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [queued]>
[2022-12-13 22:58:23,367] {taskinstance.py:1017} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 22:58:23,367] {taskinstance.py:1018} INFO - Starting attempt 1 of 1
[2022-12-13 22:58:23,367] {taskinstance.py:1019} INFO - 
--------------------------------------------------------------------------------
[2022-12-13 22:58:23,381] {taskinstance.py:1038} INFO - Executing <Task(PythonOperator): generate_bmi_criteria> on 2022-11-14T15:00:00+00:00
[2022-12-13 22:58:23,386] {standard_task_runner.py:51} INFO - Started process 2128 to run task
[2022-12-13 22:58:23,389] {standard_task_runner.py:75} INFO - Running: ['airflow', 'tasks', 'run', 'pyspark_bmi', 'generate_bmi_criteria', '2022-11-14T15:00:00+00:00', '--job-id', '5', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/pyspark_bmi.py', '--cfg-path', '/tmp/tmpj7ag75f8']
[2022-12-13 22:58:23,391] {standard_task_runner.py:76} INFO - Job 5: Subtask generate_bmi_criteria
[2022-12-13 22:58:23,426] {logging_mixin.py:103} INFO - Running <TaskInstance: pyspark_bmi.generate_bmi_criteria 2022-11-14T15:00:00+00:00 [running]> on host e696ef1fe0ba
[2022-12-13 22:58:23,458] {taskinstance.py:1232} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=pyspark_bmi
AIRFLOW_CTX_TASK_ID=generate_bmi_criteria
AIRFLOW_CTX_EXECUTION_DATE=2022-11-14T15:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=backfill__2022-11-14T15:00:00+00:00
[2022-12-13 22:58:24,006] {pyspark_bmi.py:61} INFO - Job submitted successfully. Driver id is driver-20221213225823-0000
[2022-12-13 22:58:39,211] {pyspark_bmi.py:74} INFO - Job is finished. Moving to next task
[2022-12-13 22:58:39,211] {python.py:118} INFO - Done. Returned value was: None
[2022-12-13 22:58:39,221] {taskinstance.py:1142} INFO - Marking task as SUCCESS. dag_id=pyspark_bmi, task_id=generate_bmi_criteria, execution_date=20221114T150000, start_date=20221213T225823, end_date=20221213T225839
[2022-12-13 22:58:39,249] {taskinstance.py:1195} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-12-13 22:58:39,277] {local_task_job.py:118} INFO - Task exited with return code 0
